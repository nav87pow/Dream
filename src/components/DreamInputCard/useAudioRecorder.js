// src/components/DreamInputCard/useAudioRecorder.js
import { useCallback, useRef, useState } from "react";

// ğŸ‘‡ ×‘×¡×™×¡ ×œ-API: ×× ×¡×” REACT_APP_API_URL, ××—×¨×ª ××—×œ×™×˜ ×œ×¤×™ ×“×•××™×™×Ÿ
const API_BASE_URL =
  process.env.REACT_APP_API_URL ||
  (window.location.hostname === "localhost"
    ? "http://localhost:4000"
    : "https://dream-eyyq.onrender.com");

/**
 * useAudioRecorder
 *
 * ××§×œ×™×˜ ××•×“×™×• ××”××™×§×¨×•×¤×•×Ÿ, ×©×•××¨ ××ª ×”×”×§×œ×˜×” ×›-buffer,
 * ×•×©×•×œ×— ××ª ×›×œ ×”×”×§×œ×˜×” ×‘×¤×¢× ××—×ª ×œ×©×¨×ª ×”×ª××œ×•×œ
 * ×›×©× ×œ×—×¥ Pause ××• Stop.
 *
 * ×”-API:
 * useAudioRecorder({ onTranscriptionChunk, language })
 * ××—×–×™×¨: { startRecording, pauseRecording, resumeRecording, stopRecording, isRecording, isPaused }
 */

export default function useAudioRecorder(options = {}) {
  const { onTranscriptionChunk, language } = options;

  const mediaRecorderRef = useRef(null);
  const streamRef = useRef(null);
  const chunksRef = useRef([]); // ××•×¡×£ ××ª ×›×œ ×”-chunks ×©×œ ×”×¡×©×Ÿ

  // ×˜×§×¡×˜ ××¦×˜×‘×¨ ×©×œ ×”×”×§×œ×˜×” ×”× ×•×›×—×™×ª (×××¤×¡ ×¢× start ×—×“×©, ××‘×œ × ×©××¨ ××—×•×¥ ×œ-hook ×‘-baseTextRef)
  const sessionTextRef = useRef("");

  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);

  // --- ×¤×•× ×§×¦×™×” ×¤× ×™××™×ª: ×©×œ×™×—×” ×œ×©×¨×ª ×©×œ Blob ××—×“ ××œ× ---
  const transcribeBlob = useCallback(
    async (blob) => {
      try {
        const formData = new FormData();
        formData.append("file", blob, "audio.webm");

        if (language) {
          formData.append("language", language);
        }

        const res = await fetch(`${API_BASE_URL}/api/transcribe`, {
          method: "POST",
          body: formData,
        });

        if (!res.ok) {
          console.error(
            "[useAudioRecorder] /api/transcribe failed:",
            res.status
          );
          return;
        }

        const data = await res.json();
        const text = (data && data.text) || "";

        if (!text.trim()) {
          return;
        }

        // ×¢×“×›×•×Ÿ ×”××¦×˜×‘×¨ ×©×œ ×”×¡×©×Ÿ
        if (!sessionTextRef.current) {
          sessionTextRef.current = text.trim();
        } else {
          const needsSpace =
            !sessionTextRef.current.endsWith(" ") && !text.startsWith(" ");

          sessionTextRef.current =
            sessionTextRef.current +
            (needsSpace ? " " : "") +
            text.trim();
        }

        if (typeof onTranscriptionChunk === "function") {
          onTranscriptionChunk(sessionTextRef.current);
        }
      } catch (err) {
        console.error("[useAudioRecorder] transcribeBlob error:", err);
      }
    },
    [language, onTranscriptionChunk]
  );

  // --- ×”×ª×—×œ×ª ×”×§×œ×˜×” ---
  const startRecording = useCallback(async () => {
    if (isRecording) return;

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      const recorder = new MediaRecorder(stream, {
        mimeType: "audio/webm",
      });

      chunksRef.current = []; // ××™×¤×•×¡

      recorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      recorder.onerror = (err) => {
        console.error("[useAudioRecorder] MediaRecorder error:", err);
      };

      recorder.onstop = async () => {
        // ×›×©×¢×•×¦×¨×™× â€“ ××—×‘×¨×™× ××ª ×›×œ ×”-chunks ×•×©×•×œ×—×™× ×œ×©×¨×ª
        if (!chunksRef.current.length) {
          return;
        }

        const blob = new Blob(chunksRef.current, { type: "audio/webm" });
        const currentChunks = [...chunksRef.current];
        chunksRef.current = [];

        // ×©×•×œ×—×™× ××ª ×”-blob ×”××œ× ×œ×ª××œ×•×œ
        await transcribeBlob(blob);
      };

      mediaRecorderRef.current = recorder;
      recorder.start(); // ×‘×œ×™ timeslice â€“ chunk ××—×“ ×’×“×•×œ ×¢×“ ×¢×¦×™×¨×”

      setIsRecording(true);
      setIsPaused(false);
    } catch (err) {
      console.error("[useAudioRecorder] getUserMedia error:", err);
    }
  }, [isRecording, transcribeBlob]);

  // --- Pause: ×¢×¦×™×¨×” + ×ª××œ×•×œ ×”×”×§×œ×˜×” ×¢×“ ×¢×›×©×™×• ---
  const pauseRecording = useCallback(() => {
    const recorder = mediaRecorderRef.current;
    if (!recorder || !isRecording || isPaused) return;

    try {
      if (recorder.state !== "inactive") {
        recorder.stop(); // ×™×¤×¢×™×œ onstop â†’ transcribeBlob
      }
      setIsRecording(false);
      setIsPaused(true);
    } catch (err) {
      console.error("[useAudioRecorder] pause error:", err);
    }
  }, [isRecording, isPaused]);

  // --- Resume: ××ª×—×™×œ ×¡×©×Ÿ ×—×“×©, ×¢×œ ×’×‘×™ ×”×˜×§×¡×˜ ×©×›×‘×¨ ×ª×•××œ×œ ---
  const resumeRecording = useCallback(async () => {
    if (isRecording) return;

    setIsPaused(false);
    await startRecording();
  }, [isRecording, startRecording]);

  // --- Stop: ×¢×¦×™×¨×” ××œ××” + ×¡×’×™×¨×ª ××™×§×¨×•×¤×•×Ÿ ---
  const stopRecording = useCallback(() => {
    const recorder = mediaRecorderRef.current;

    try {
      if (recorder && recorder.state !== "inactive") {
        recorder.stop(); // onstop ×™×“××’ ×œ×ª××œ×•×œ
      }
    } catch (err) {
      console.error("[useAudioRecorder] stop error:", err);
    } finally {
      mediaRecorderRef.current = null;
      setIsRecording(false);
      setIsPaused(false);

      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
        streamRef.current = null;
      }

      // ×× ×ª×¨×¦×” ×œ××¤×¡ ××ª ×”×˜×§×¡×˜ ×©×œ ×”×¡×©×Ÿ ×‘×¡×•×£ ×œ×—×œ×•×˜×™×Ÿ:
      // sessionTextRef.current = "";
    }
  }, []);

  return {
    startRecording,
    pauseRecording,
    resumeRecording,
    stopRecording,
    isRecording,
    isPaused,
  };
}
