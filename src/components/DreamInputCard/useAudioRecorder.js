// src/components/DreamInputCard/useAudioRecorder.js
import { useCallback, useRef, useState } from "react";

/**
 * useAudioRecorder
 *
 * ××—×¨××™ ×œ×”×§×œ×˜×ª ××•×“×™×• ×ž×”×ž×™×§×¨×•×¤×•×Ÿ, ×©×œ×™×—×ª chunk ×›×œ ×©× ×™×” ×œ×©×¨×ª ×”×ª×ž×œ×•×œ,
 * ×•×”×—×–×¨×ª ×˜×§×¡×˜ ×ž×¦×˜×‘×¨ ×©×œ ×”×”×§×œ×˜×” ×”× ×•×›×—×™×ª ×“×¨×š onTranscriptionChunk.
 *
 * ×”Ö¾API × ×©××¨ ×›×ž×• ×©×”×™×” ×‘×“REAMInputCard:
 * useAudioRecorder({ onTranscriptionChunk })
 * ×ž×—×–×™×¨: { startRecording, pauseRecording, resumeRecording, stopRecording }
 */

export default function useAudioRecorder(options = {}) {
  const { onTranscriptionChunk, language } = options;

  const mediaRecorderRef = useRef(null);
  const streamRef = useRef(null);

  // ×˜×§×¡×˜ ×ž×¦×˜×‘×¨ ×©×œ ×”×”×§×œ×˜×” ×”× ×•×›×—×™×ª (×ž××¤×¡ ×¢× start ×—×“×©)
  const sessionTextRef = useRef("");

  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);

  // --- ×¤×•× ×§×¦×™×” ×¤× ×™×ž×™×ª: ×©×œ×™×—×” ×œ×©×¨×ª ×©×œ chunk ×™×—×™×“ ---
  const transcribeChunk = useCallback(
    async (blob) => {
      try {
        const formData = new FormData();
        formData.append("file", blob, "chunk.webm");

        // ×× ×™×© ×©×¤×ª ×”×§×©×¨ â€“ ×ž×•×¡×™×¤×™×, ××—×¨×ª ×”×©×¨×ª ×™×ª×¤×•×¡ ×‘×¨×™×¨×ª ×ž×—×“×œ (English)
        if (language) {
          formData.append("language", language);
        }

        const res = await fetch("/api/transcribe", {
          method: "POST",
          body: formData,
        });

        if (!res.ok) {
          console.error("[useAudioRecorder] /api/transcribe failed:", res.status);
          return;
        }

        const data = await res.json();
        const chunkText = (data && data.text) || "";

        if (!chunkText.trim()) {
          return;
        }

        // ×¢×“×›×•×Ÿ ×”×ž×¦×˜×‘×¨ ×©×œ ×”×¡×©×Ÿ
        if (!sessionTextRef.current) {
          sessionTextRef.current = chunkText.trim();
        } else {
          // ×ž×•×¡×™×¤×™× ×¨×•×•×— ×× ×¦×¨×™×š
          const needsSpace =
            !sessionTextRef.current.endsWith(" ") && !chunkText.startsWith(" ");

          sessionTextRef.current =
            sessionTextRef.current + (needsSpace ? " " : "") + chunkText.trim();
        }

        // ×”×—×–×¨×” ×œ×ž×¢×œ×” â€“ DREAMInputCard ×›×‘×¨ ×™×•×“×¢ ×œ×—×‘×¨ ×¢×œ ×‘×¡×™×¡ baseTextRef
        if (typeof onTranscriptionChunk === "function") {
          onTranscriptionChunk(sessionTextRef.current);
        }
      } catch (err) {
        console.error("[useAudioRecorder] transcribeChunk error:", err);
      }
    },
    [language, onTranscriptionChunk]
  );

  // --- ×”×ª×—×œ×ª ×”×§×œ×˜×” ---
  const startRecording = useCallback(async () => {
    if (isRecording) return;

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      // MediaRecorder ×¢× ×—×œ×•×§×” ×œ-chunk ××—×“ ×›×œ 1000ms
      const recorder = new MediaRecorder(stream, {
        mimeType: "audio/webm",
      });

      // ××™×¤×•×¡ ×˜×§×¡×˜ ×”×¡×©×Ÿ ×‘×ª×—×™×œ×ª ×”×§×œ×˜×”
      sessionTextRef.current = "";

      recorder.ondataavailable = async (event) => {
        // ×”×¤×•× ×§×¦×™×” ×”×–××ª × ×§×¨××ª ×›×œ ×¤×¢× ×©× ×•×¦×¨ chunk (×›×œ ×©× ×™×”)
        if (!event.data || event.data.size === 0) return;

        // ×©×•×œ×—×™× ××ª ×”-chunk ×œ×©×¨×ª
        await transcribeChunk(event.data);
      };

      recorder.onerror = (err) => {
        console.error("[useAudioRecorder] MediaRecorder error:", err);
      };

      mediaRecorderRef.current = recorder;
      recorder.start(1000); // ðŸ‘ˆ ×›×œ 1000ms × ×§×‘×œ ondataavailable
      setIsRecording(true);
      setIsPaused(false);
    } catch (err) {
      console.error("[useAudioRecorder] getUserMedia error:", err);
    }
  }, [isRecording, transcribeChunk]);

  // --- Pause ---
  const pauseRecording = useCallback(() => {
    const recorder = mediaRecorderRef.current;
    if (!recorder || !isRecording || isPaused) return;

    try {
      if (typeof recorder.pause === "function") {
        recorder.pause();
      } else {
        // ×× ×”×“×¤×“×¤×Ÿ ×œ× ×ª×•×ž×š â€“ ×  fallback ×œ-stop ×—×œ×§×™ (× ×™×ª×Ÿ ×œ×©×¤×¨ ×‘×”×ž×©×š)
        recorder.stop();
      }
      setIsPaused(true);
    } catch (err) {
      console.error("[useAudioRecorder] pause error:", err);
    }
  }, [isRecording, isPaused]);

  // --- Resume ---
  const resumeRecording = useCallback(async () => {
    const recorder = mediaRecorderRef.current;

    // ×× ×™×© pause ×ž×•×‘× ×” â€“ ×ž×©×ª×ž×©×™× ×‘×•
    if (recorder && typeof recorder.resume === "function") {
      try {
        recorder.resume();
        setIsPaused(false);
        return;
      } catch (err) {
        console.error("[useAudioRecorder] resume error:", err);
      }
    }

    // fallback: ×× ××™×Ÿ recorder ×¤×¢×™×œ â€“ × ×ª×—×™×œ ×”×§×œ×˜×” ×—×“×©×” ×ž××•×ª×• stream
    if (!isRecording) {
      await startRecording();
    } else {
      setIsPaused(false);
    }
  }, [isRecording, startRecording]);

  // --- Stop ×œ×’×ž×¨×™ ---
  const stopRecording = useCallback(() => {
    const recorder = mediaRecorderRef.current;
    if (!recorder) return;

    try {
      if (recorder.state !== "inactive") {
        recorder.stop();
      }
    } catch (err) {
      console.error("[useAudioRecorder] stop error:", err);
    } finally {
      mediaRecorderRef.current = null;
      setIsRecording(false);
      setIsPaused(false);

      // ×¢×¦×™×¨×ª ×”×ž×™×§×¨×•×¤×•×Ÿ
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
        streamRef.current = null;
      }
    }
  }, []);

  return {
    startRecording,
    pauseRecording,
    resumeRecording,
    stopRecording,
    isRecording,
    isPaused,
  };
}
